import cv2
from ultralytics import YOLO

# --- C·∫§U H√åNH ---
MODEL_PATH = 'models/best.pt'  # ƒê∆∞·ªùng d·∫´n ƒë·∫øn file model
CONFIDENCE_THRESHOLD = 0.5     # ƒê·ªô tin c·∫≠y t·ªëi thi·ªÉu (0.5 = 50%)

EMOTION_MAP = {
    'anger': 'Gi·∫≠n d·ªØ',
    'content': 'M√£n nguy·ªán',
    'disgust': 'Gh√™ t·ªüm',
    'fear': 'S·ª£ h√£i',
    'happy': 'H·∫°nh ph√∫c',
    'neutral': 'B√¨nh th∆∞·ªùng',
    'sad': 'Bu·ªìn b√£',
    'surprise': 'Ng·∫°c nhi√™n'
}

# M√†u s·∫Øc cho t·ª´ng c·∫£m x√∫c (BGR format)
COLORS = {
    'anger': (0, 0, 255),      # ƒê·ªè
    'happy': (0, 255, 0),      # L·ª•c
    'sad': (255, 0, 0),        # Lam
    'neutral': (128, 128, 128) # X√°m
    # C√°c m√†u kh√°c m·∫∑c ƒë·ªãnh s·∫Ω l√† tr·∫Øng
}

def main():
    # 1. Load Model
    print("‚è≥ ƒêang t·∫£i model...")
    try:
        model = YOLO(MODEL_PATH)
        print("‚úÖ T·∫£i model th√†nh c√¥ng!")
    except Exception as e:
        print(f"‚ùå L·ªói kh√¥ng t√¨m th·∫•y model: {e}")
        return

    # 2. M·ªü Webcam (S·ªë 0 l√† cam m·∫∑c ƒë·ªãnh, n·∫øu kh√¥ng l√™n th·ª≠ ƒë·ªïi th√†nh 1)
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("‚ùå Kh√¥ng th·ªÉ m·ªü Webcam.")
        return

    print("üé• ƒêang ch·∫°y camera... Nh·∫•n ph√≠m 'q' ƒë·ªÉ tho√°t.")

    while True:
        ret, frame = cap.read()
        if not ret:
            break

        # 3. Nh·∫≠n di·ªán
        # stream=True gi√∫p x·ª≠ l√Ω nhanh h∆°n cho video
        results = model.predict(frame, conf=CONFIDENCE_THRESHOLD, verbose=False)

        # 4. V·∫Ω k·∫øt qu·∫£ l√™n m√†n h√¨nh
        for result in results:
            boxes = result.boxes
            for box in boxes:
                # L·∫•y t·ªça ƒë·ªô v√† nh√£n
                x1, y1, x2, y2 = map(int, box.xyxy[0])
                cls_id = int(box.cls[0])
                cls_name = model.names[cls_id] # T√™n g·ªëc (anger, happy...)
                
                # Chuy·ªÉn sang ti·∫øng Vi·ªát
                label_vi = EMOTION_MAP.get(cls_name, cls_name)
                conf = float(box.conf[0])
                
                # Ch·ªçn m√†u s·∫Øc
                color = COLORS.get(cls_name, (0, 255, 255)) # M·∫∑c ƒë·ªãnh l√† V√†ng

                # V·∫Ω h√¨nh ch·ªØ nh·∫≠t
                cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
                
                # Vi·∫øt ch·ªØ l√™n tr√™n
                text = f"{label_vi} ({conf:.1f})"
                cv2.putText(frame, text, (x1, y1 - 10), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)

        # 5. Hi·ªÉn th·ªã
        cv2.imshow('YOLOv8 Emotion Detection', frame)

        # B·∫•m 'q' ƒë·ªÉ tho√°t
        if cv2.waitKey(1) & 0xFF == ord('q'):
            break

    cap.release()
    cv2.destroyAllWindows()

if __name__ == '__main__':
    main()
import streamlit as st
from ultralytics import YOLO
from PIL import Image
import numpy as np

MODEL_PATH = 'models/best.pt' 

EMOTION_MAP = {
    'anger': 'Gi·∫≠n d·ªØ',
    'content': 'M√£n nguy·ªán',
    'disgust': 'Gh√™ t·ªüm',
    'fear': 'S·ª£ h√£i',
    'happy': 'H·∫°nh ph√∫c',
    'neutral': 'B√¨nh th∆∞·ªùng',
    'sad': 'Bu·ªìn b√£',
    'surprise': 'Ng·∫°c nhi√™n'
}

@st.cache_resource
def load_model():
    return YOLO(MODEL_PATH)

try:
    model = load_model()
except Exception as e:
    st.error(f"‚ùå Kh√¥ng t√¨m th·∫•y file model t·∫°i: {MODEL_PATH}")
    st.stop()

st.title("üòä H·ªá th·ªëng Nh·∫≠n di·ªán C·∫£m x√∫c YOLOv8")
st.write("ƒê·ªì √°n - Sinh vi√™n: Tr·∫ßn Xu√¢n ƒê·ª©c")

tab1, tab2 = st.tabs(["üñºÔ∏è Nh·∫≠n di·ªán qua ·∫¢nh", "üì∑ Nh·∫≠n di·ªán qua Webcam"])

# --- TAB 1: UPLOAD ·∫¢NH ---
with tab1:
    st.header("T·∫£i ·∫£nh l√™n ƒë·ªÉ nh·∫≠n di·ªán")
    uploaded_file = st.file_uploader("Ch·ªçn m·ªôt b·ª©c ·∫£nh...", type=['jpg', 'jpeg', 'png'])

    if uploaded_file is not None:
        # Hi·ªÉn th·ªã ·∫£nh g·ªëc
        image = Image.open(uploaded_file)
        st.image(image, caption='·∫¢nh ƒë√£ t·∫£i l√™n', width="stretch")
        
        # N√∫t b·∫•m x·ª≠ l√Ω
        if st.button('üîç Ph√¢n t√≠ch C·∫£m x√∫c ngay'):
            with st.spinner('ƒêang ph√¢n t√≠ch...'):
                # D·ª± ƒëo√°n
                results = model.predict(image, conf=0.20, iou=0.5, imgsz=1280, agnostic_nms=True, augment=True)
                
                # V·∫Ω k·∫øt qu·∫£ l√™n ·∫£nh
                # results[0].plot() tr·∫£ v·ªÅ m·∫£ng numpy (BGR), c·∫ßn chuy·ªÉn sang RGB ƒë·ªÉ hi·ªÉn th·ªã ƒë√∫ng m√†u
                res_plotted = results[0].plot()[:, :, ::-1]
                
                # Hi·ªÉn th·ªã k·∫øt qu·∫£
                st.success("Xong!")
                st.image(res_plotted, caption='K·∫øt qu·∫£ nh·∫≠n di·ªán', width="stretch")
                
                # In chi ti·∫øt ra text
                st.subheader("Chi ti·∫øt:")
                for box in results[0].boxes:
                    cls_id = int(box.cls[0])
                    label = model.names[cls_id]
                    vn_label = EMOTION_MAP.get(label, label)
                    conf = float(box.conf[0])
                    st.write(f"- Ph√°t hi·ªán: **{vn_label}** (ƒê·ªô tin c·∫≠y: {conf:.1%})")

# --- TAB 2: WEBCAM ---
with tab2:
    st.header("Ch·ª•p ·∫£nh t·ª´ Webcam")
    st.warning("L∆∞u √Ω: Tr√™n tr√¨nh duy·ªát web, b·∫°n c·∫ßn nh·∫•n n√∫t 'Take Photo' ƒë·ªÉ ch·ª•p ·∫£nh tƒ©nh v√† g·ª≠i ƒëi ph√¢n t√≠ch.")
    
    # Widget Webcam c·ªßa Streamlit
    img_file_buffer = st.camera_input("B·∫Øt ƒë·∫ßu!")

    if img_file_buffer is not None:
        # X·ª≠ l√Ω khi c√≥ ·∫£nh ch·ª•p
        image = Image.open(img_file_buffer)
        
        # D·ª± ƒëo√°n
        results = model.predict(image, conf=0.20, iou=0.5, imgsz=1280, agnostic_nms=True, augment=True)
        res_plotted = results[0].plot()[:, :, ::-1]
        
        st.image(res_plotted, caption='K·∫øt qu·∫£ t·ª´ Webcam', width="stretch")